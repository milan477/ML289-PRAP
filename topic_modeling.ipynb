{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748a8d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# from src.io.read import read_pdfs, _read_single_pdf\n",
    "from src.config import DATA_DIR\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\n",
    "    \"ignore\",\n",
    "    category=FutureWarning,\n",
    "    module=\"transformers\"\n",
    ")\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d093cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _read_single_pdf_pytesseract(path: Path):\n",
    "    print(f\"Reading {path.name} with pytesseract\")\n",
    "    pages = convert_from_path(path)\n",
    "    \n",
    "    data = []\n",
    "    for page in pages[:1]:  # limit to first 10 pages for now\n",
    "        print(f'Processing page {len(data)+1} / {len(pages)}')\n",
    "        data.append(\n",
    "            pd.DataFrame(\n",
    "                pytesseract.image_to_data(\n",
    "                    image = page,\n",
    "                    lang = 'eng',\n",
    "                    output_type=pytesseract.Output.DICT)\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "    return pages[0], data[0] # TODO: limited to first page for now\n",
    "\n",
    "\n",
    "def _read_pdf(path: Path, method = 'pytesseract'):\n",
    "    pdfs = []\n",
    "    if method == 'pytesseract':\n",
    "        for i in tqdm(range(30)):\n",
    "            pdfs.append(_read_single_pdf_pytesseract(path / f\"record{i}.pdf\"))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown method {method} for reading PDF\")\n",
    "    return zip(*pdfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caf03d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading record0.pdf with pytesseract\n",
      "Processing page 1 / 1\n",
      "Reading record1.pdf with pytesseract\n",
      "Processing page 1 / 2\n",
      "Reading record2.pdf with pytesseract\n",
      "Processing page 1 / 4\n",
      "Reading record3.pdf with pytesseract\n",
      "Processing page 1 / 194\n",
      "Reading record4.pdf with pytesseract\n",
      "Processing page 1 / 24\n",
      "Reading record5.pdf with pytesseract\n",
      "Processing page 1 / 22\n",
      "Reading record6.pdf with pytesseract\n",
      "Processing page 1 / 27\n",
      "Reading record7.pdf with pytesseract\n",
      "Processing page 1 / 17\n",
      "Reading record8.pdf with pytesseract\n",
      "Processing page 1 / 11\n",
      "Reading record9.pdf with pytesseract\n",
      "Processing page 1 / 11\n",
      "Reading record10.pdf with pytesseract\n",
      "Processing page 1 / 24\n",
      "Reading record11.pdf with pytesseract\n",
      "Processing page 1 / 24\n",
      "Reading record12.pdf with pytesseract\n",
      "Processing page 1 / 13\n",
      "Reading record13.pdf with pytesseract\n",
      "Processing page 1 / 13\n",
      "Reading record14.pdf with pytesseract\n",
      "Processing page 1 / 6\n",
      "Reading record15.pdf with pytesseract\n",
      "Processing page 1 / 11\n",
      "Reading record16.pdf with pytesseract\n",
      "Processing page 1 / 7\n",
      "Reading record17.pdf with pytesseract\n",
      "Processing page 1 / 5\n",
      "Reading record18.pdf with pytesseract\n",
      "Processing page 1 / 49\n",
      "Reading record19.pdf with pytesseract\n",
      "Processing page 1 / 160\n",
      "Reading record20.pdf with pytesseract\n",
      "Processing page 1 / 4\n",
      "Reading record21.pdf with pytesseract\n",
      "Processing page 1 / 1\n",
      "Reading record22.pdf with pytesseract\n",
      "Processing page 1 / 5\n",
      "Reading record23.pdf with pytesseract\n",
      "Processing page 1 / 4\n",
      "Reading record24.pdf with pytesseract\n",
      "Processing page 1 / 49\n",
      "Reading record25.pdf with pytesseract\n",
      "Processing page 1 / 4\n",
      "Reading record26.pdf with pytesseract\n",
      "Processing page 1 / 1\n",
      "Reading record27.pdf with pytesseract\n",
      "Processing page 1 / 21\n",
      "Reading record28.pdf with pytesseract\n",
      "Processing page 1 / 92\n",
      "Reading record29.pdf with pytesseract\n",
      "Processing page 1 / 2\n"
     ]
    }
   ],
   "source": [
    "pages, ocrs = _read_pdf(DATA_DIR, method='pytesseract')\n",
    "\n",
    "# page, ocr_data = _read_single_pdf_pytesseract(DATA_DIR / f\"record{4}.pdf\")\n",
    "\n",
    "# len(ocr_data['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4db95ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)\n",
    "len(ocrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "821189e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes(ocr_data, page):\n",
    "  coordinates = ocr_data[['left', 'top', 'width', 'height']]\n",
    "  actual_boxes = []\n",
    "  for idx, row in coordinates.iterrows():\n",
    "      x, y, w, h = tuple(row) # the row comes in (left, top, width, height) format\n",
    "      actual_box = [x, y, x+w, y+h] # we turn it into (left, top, left+width, top+height) to get the actual box \n",
    "      actual_boxes.append(actual_box)\n",
    "\n",
    "  draw = ImageDraw.Draw(page, \"RGB\")\n",
    "  for box in actual_boxes:\n",
    "    draw.rectangle(box, outline='red')\n",
    "  return page\n",
    "\n",
    "def concatenate(s):\n",
    "    return ' '.join([str(t) for t in s if str(t) != 'nan' and str(t).strip() != ''])\n",
    "\n",
    "def display_by_line(ocr_data):\n",
    "    lines = ocr_data.groupby(\n",
    "        ['page_num','block_num','line_num'])[['text']].agg(concatenate)\n",
    "    return str('\\n'.join(lines['text'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fd55b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_text_to_boxes(ocr_data: pd.DataFrame):\n",
    "    words = []\n",
    "    boxes = []\n",
    "\n",
    "    page_sizes = ocr_data[['width', 'height']].max().values\n",
    "    w, h = page_sizes[0], page_sizes[1]\n",
    "\n",
    "    for i, text in enumerate(ocr_data['text']):\n",
    "        \n",
    "        if text.strip() == \"\" and ocr_data['level'][i] != 5:\n",
    "            continue\n",
    "        words.append(text)\n",
    "        x0 = int(ocr_data['left'][i] / w * 1000)\n",
    "        y0 = int(ocr_data['top'][i] / h * 1000)\n",
    "        x1 = int((ocr_data['left'][i] + ocr_data['width'][i]) / w * 1000)\n",
    "        y1 = int((ocr_data['top'][i] + ocr_data['height'][i]) / h * 1000)\n",
    "        boxes.append([x0, y0, x1, y1])\n",
    "\n",
    "    print(f'Converted OCR data into {len(words)} words and {len(boxes)} boxes')\n",
    "    return words, boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a931e5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, LayoutLMForQuestionAnswering, AutoModel, LayoutLMForQuestionAnswering\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "model = AutoModel.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "\n",
    "tokenizer_for_QA = AutoTokenizer.from_pretrained(\"impira/layoutlm-document-qa\")\n",
    "model_for_QA = LayoutLMForQuestionAnswering.from_pretrained(\"impira/layoutlm-document-qa\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851c2f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(ocrs):\n",
    "    embeddings = []\n",
    "    for ocr_data in ocrs:\n",
    "        words, boxes = convert_text_to_boxes(ocr_data)\n",
    "\n",
    "        encoding = tokenizer(\n",
    "            words,\n",
    "            boxes=boxes,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoding[\"bbox\"] = torch.tensor([boxes])\n",
    "        pd.DataFrame(encoding).head()\n",
    "\n",
    "        bbox = []\n",
    "        for i, s, w in zip(encoding.input_ids[0], encoding.sequence_ids(0), encoding.word_ids(0)):\n",
    "            if s == 1 and w is not None:\n",
    "                bbox.append(boxes[w])\n",
    "            elif i == tokenizer.sep_token_id:\n",
    "                bbox.append([1000] * 4)\n",
    "            else:\n",
    "                bbox.append([0] * 4)\n",
    "        encoding[\"bbox\"] = torch.tensor([bbox])\n",
    "\n",
    "        outputs = model(**encoding)\n",
    "        embedding = outputs.last_hidden_state.detach().numpy()\n",
    "        embeddings.append(embedding.mean(axis=1))\n",
    "\n",
    "    return np.array(embeddings).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b9ddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted OCR data into 117 words and 117 boxes\n",
      "Converted OCR data into 283 words and 283 boxes\n",
      "Converted OCR data into 490 words and 490 boxes\n",
      "Converted OCR data into 294 words and 294 boxes\n",
      "Converted OCR data into 164 words and 164 boxes\n",
      "Converted OCR data into 403 words and 403 boxes\n",
      "Converted OCR data into 95 words and 95 boxes\n",
      "Converted OCR data into 1 words and 1 boxes\n",
      "Converted OCR data into 125 words and 125 boxes\n",
      "Converted OCR data into 125 words and 125 boxes\n",
      "Converted OCR data into 374 words and 374 boxes\n",
      "Converted OCR data into 374 words and 374 boxes\n",
      "Converted OCR data into 127 words and 127 boxes\n",
      "Converted OCR data into 127 words and 127 boxes\n",
      "Converted OCR data into 221 words and 221 boxes\n",
      "Converted OCR data into 164 words and 164 boxes\n",
      "Converted OCR data into 222 words and 222 boxes\n",
      "Converted OCR data into 118 words and 118 boxes\n",
      "Converted OCR data into 159 words and 159 boxes\n",
      "Converted OCR data into 291 words and 291 boxes\n",
      "Converted OCR data into 418 words and 418 boxes\n",
      "Converted OCR data into 47 words and 47 boxes\n",
      "Converted OCR data into 118 words and 118 boxes\n",
      "Converted OCR data into 121 words and 121 boxes\n",
      "Converted OCR data into 159 words and 159 boxes\n",
      "Converted OCR data into 418 words and 418 boxes\n",
      "Converted OCR data into 47 words and 47 boxes\n",
      "Converted OCR data into 237 words and 237 boxes\n",
      "Converted OCR data into 155 words and 155 boxes\n",
      "Converted OCR data into 518 words and 518 boxes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(30, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = get_embeddings(ocrs)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c2b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_a_question(question = \"what kind/type/category of document is this?\", ocrs = ocrs):\n",
    "    types = []\n",
    "    for ocr_data in tqdm(ocrs):\n",
    "        words, boxes = convert_text_to_boxes(ocr_data)\n",
    "\n",
    "        encoding = tokenizer_for_QA(\n",
    "            question.split(),\n",
    "            words,\n",
    "            is_split_into_words=True,\n",
    "            return_token_type_ids=True,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "        )\n",
    "        encoding[\"bbox\"] = torch.tensor([boxes])\n",
    "\n",
    "        bbox = []\n",
    "        for i, s, w in zip(encoding.input_ids[0], encoding.sequence_ids(0), encoding.word_ids(0)):\n",
    "            if s == 1 and w is not None:\n",
    "                bbox.append(boxes[w])\n",
    "            elif i == tokenizer.sep_token_id:\n",
    "                bbox.append([1000] * 4)\n",
    "            else:\n",
    "                bbox.append([0] * 4)\n",
    "        encoding[\"bbox\"] = torch.tensor([bbox])\n",
    "\n",
    "        outputs = model_for_QA(**encoding)\n",
    "        start_scores = outputs.start_logits\n",
    "        end_scores = outputs.end_logits\n",
    "\n",
    "        start_probabilities = torch.softmax(start_scores, dim=1).squeeze()\n",
    "        end_probabilities = torch.softmax(end_scores, dim=1).squeeze()\n",
    "\n",
    "        topk_start = torch.topk(start_probabilities, k=3)[1].squeeze()\n",
    "        topk_end = torch.topk(end_probabilities, k=3)[1].squeeze()\n",
    "\n",
    "        word_ids = encoding.word_ids(0)\n",
    "        possible_answers = []\n",
    "        for start_token, end_token in zip(topk_start, topk_end):\n",
    "            if start_probabilities[start_token] > 0.1 and end_probabilities[end_token] > 0.1:\n",
    "                start_word, end_word = word_ids[start_token], word_ids[end_token]\n",
    "\n",
    "                if start_word is not None and end_word is not None and start_word <= end_word and end_word < start_word + 10:\n",
    "                    possible_answers.append(\" \".join(words[start_word : end_word + 1]))\n",
    "\n",
    "        types.append(possible_answers if len(possible_answers) > 0 else [\"N/A\"])\n",
    "\n",
    "    return types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c0857eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted OCR data into 117 words and 117 boxes\n",
      "Converted OCR data into 283 words and 283 boxes\n",
      "Converted OCR data into 490 words and 490 boxes\n",
      "Converted OCR data into 294 words and 294 boxes\n",
      "Converted OCR data into 164 words and 164 boxes\n",
      "Converted OCR data into 403 words and 403 boxes\n",
      "Converted OCR data into 95 words and 95 boxes\n",
      "Converted OCR data into 1 words and 1 boxes\n",
      "Converted OCR data into 125 words and 125 boxes\n",
      "Converted OCR data into 125 words and 125 boxes\n",
      "Converted OCR data into 374 words and 374 boxes\n",
      "Converted OCR data into 374 words and 374 boxes\n",
      "Converted OCR data into 127 words and 127 boxes\n",
      "Converted OCR data into 127 words and 127 boxes\n",
      "Converted OCR data into 221 words and 221 boxes\n",
      "Converted OCR data into 164 words and 164 boxes\n",
      "Converted OCR data into 222 words and 222 boxes\n",
      "Converted OCR data into 118 words and 118 boxes\n",
      "Converted OCR data into 159 words and 159 boxes\n",
      "Converted OCR data into 291 words and 291 boxes\n",
      "Converted OCR data into 418 words and 418 boxes\n",
      "Converted OCR data into 47 words and 47 boxes\n",
      "Converted OCR data into 118 words and 118 boxes\n",
      "Converted OCR data into 121 words and 121 boxes\n",
      "Converted OCR data into 159 words and 159 boxes\n",
      "Converted OCR data into 418 words and 418 boxes\n",
      "Converted OCR data into 47 words and 47 boxes\n",
      "Converted OCR data into 237 words and 237 boxes\n",
      "Converted OCR data into 155 words and 155 boxes\n",
      "Converted OCR data into 518 words and 518 boxes\n"
     ]
    }
   ],
   "source": [
    "possible_types = ask_a_question()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "877a5b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Cluster 0:\n",
      " - Document 10 - Possible types: ['Incident Report Report Cover Sheet']\n",
      " - Document 11 - Possible types: ['Incident Report Report Cover Sheet']\n",
      " - Document 19 - Possible types: ['Passenger Car/ Automobile']\n",
      "Cluster 1:\n",
      " - Document 12 - Possible types: ['CONTROLLED DOCUMENT - DO NOT DUPLICATE Arrest/Detention Information']\n",
      " - Document 13 - Possible types: ['CONTROLLED DOCUMENT - DO NOT DUPLICATE Arrest/Detention Information']\n",
      " - Document 18 - Possible types: ['N/A']\n",
      " - Document 24 - Possible types: ['N/A']\n",
      " - Document 27 - Possible types: ['SWORN EMPLOYEE DISCIPLINARY PACKAGE CHECKLIST']\n",
      " - Document 28 - Possible types: ['Discovery Package']\n",
      "Cluster 2:\n",
      " - Document 0 - Possible types: ['Action']\n",
      " - Document 17 - Possible types: ['ShotSpotter°']\n",
      " - Document 22 - Possible types: ['ShotSpotter°']\n",
      " - Document 23 - Possible types: ['ShotSpotter°']\n",
      "Cluster 3:\n",
      " - Document 21 - Possible types: ['Large overview']\n",
      " - Document 26 - Possible types: ['Large overview']\n",
      "Cluster 4:\n",
      " - Document 7 - Possible types: ['N/A']\n",
      "Cluster 5:\n",
      " - Document 6 - Possible types: ['Offense Type']\n",
      " - Document 8 - Possible types: ['Other']\n",
      " - Document 9 - Possible types: ['Other']\n",
      "Cluster 6:\n",
      " - Document 1 - Possible types: ['POLICE DEPARTMENT']\n",
      " - Document 2 - Possible types: ['The Police Commission']\n",
      " - Document 3 - Possible types: ['N/A']\n",
      " - Document 5 - Possible types: ['MERCED COUNTY DISTRICT ATTORNEY’S OFFICE']\n",
      " - Document 20 - Possible types: ['INFORMATION - FELONY']\n",
      " - Document 25 - Possible types: ['INFORMATION - FELONY']\n",
      " - Document 29 - Possible types: ['Supplement']\n",
      "Cluster 7:\n",
      " - Document 14 - Possible types: ['INTERVIEW']\n",
      " - Document 15 - Possible types: ['N/A']\n",
      " - Document 16 - Possible types: ['INTERVIEW WITH Interviewer: Inv. Hicks']\n",
      "Cluster 8:\n",
      " - Document 4 - Possible types: ['MEMORANDUM']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans_model = KMeans(n_clusters=9, random_state=42)\n",
    "kmeans_model.fit(embeddings)\n",
    "labels = kmeans_model.labels_\n",
    "print(len(labels))\n",
    "\n",
    "\n",
    "for label in set(labels):\n",
    "    print(f\"Cluster {label}:\")\n",
    "    for i, ocr_data in enumerate(ocrs):\n",
    "        if labels[i] == label:\n",
    "            print(f\" - Document {i} - Possible types: {possible_types[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5da4300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/milanliessens/Documents/Education/Universities/Berkeley/MEng/Fall 2025/CS 289 - ML/Grad Project/.venv/lib/python3.12/site-packages/transformers/models/layoutlmv3/feature_extraction_layoutlmv3.py:32: FutureWarning: The class LayoutLMv3FeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use LayoutLMv3ImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1642, 2152)\n"
     ]
    }
   ],
   "source": [
    "from transformers import LayoutLMv3FeatureExtractor, LayoutLMv3Model\n",
    "feature_extractor = LayoutLMv3FeatureExtractor.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "image = page.convert(\"RGB\")\n",
    "print(image.size)\n",
    "pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "7f10e01a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixel_values.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
